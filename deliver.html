<!DOCTYPE html>
<html lang="nl">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Definefase - Triple C Implementatie</title>
  <link rel="stylesheet" href="css/onderzoek.css">
</head>
<body>
  <!-- Navigatie / Header -->
  <header>
    <nav>
      <ul class="main-nav">
        <li><a href="onderzoek.html">Onderzoekspagina</a></li>
        <li><a href="discover.html">Discover</a></li>
        <li><a href="define.html" class="active">Define</a></li>
        <li><a href="develop.html">Develop</a></li>
        <li><a href="deliver.html">Deliver</a></li>
      </ul>
    </nav>
  </header>

  <!-- Introductie en Leeswijzer -->
  <section class="header-bubble">
    <h1>Deliverfase</h1>
    <p>
    Evalueren, Optimaliseren, Communiceren, Overdragen</p>
  </section>

  <!-- (Optioneel) Dynamische Inhoudsopgave -->
<div id="toc-container" class="chapter-toc">
  <h2>Inhoudsopgave</h2>
  <ul id="tocList">
    <!-- Dynamische TOC-items komen hier via JavaScript -->
  </ul>
</div>

  <!-- Hoofdinhoud in een article met collapsible cards -->
  <main class="onderzoek-page">
    <article>
  <header>
    <h1>5. Deliver-fase: Implementatie, Borging en Overdracht</h1>
  </header>
<main>
  <section>
    <h2>5.1 Inleiding</h2>
    <p>
      Waar de developfase zich kenmerkte door experimenteren en iteratief prototypen, staat de deliverfase in het teken van verfijnen, valideren en implementeren. Binnen dit onderzoek is het belangrijk om te benadrukken dit proces niet enkel draait om het opleveren van een <em>‘ding’</em> (bijv. een fysiek product of een stuk software), maar vooral om de borging van de opbrengsten in de professionele praktijk. Met andere woorden, de deliverfase verzekert dat de in de discover-, define- en develop-fases opgedane inzichten daadwerkelijk leiden tot de beoogde verbeteringen in de zorgpraktijk.
    </p>
    <p>
      In het komende hoofdstuk wordt besproken hoe in dit onderzoek de nadruk ligt op overdraagbaarheid boven een fysiek eindproduct, welke ethische implicaties (o.a. privacy, veiligheid, transparantie, kwetsbaarheid van cliënten) een belangrijke rol spelen bij het thema “AI in de zorg”, en met name op welke wijze dit onderzoek kan worden overgedragen en opgeschaald. 

    </p>
  </section>

  <section>
    <h2>5.2 Overdraagbaarheid boven een fysiek eindproduct</h2>
    <p>
De focus op de overdraagbaarheid van dit onderzoek vloeit voort uit zowel ethische als praktische overwegingen. In plaats van een ‘product’ is het eindresultaat van de dit ontwerpgerichte onderzoek een <em>“kant en klaar”</em> onderzoeks-medium. De nadruk ligt op het borgingsproces: het vastleggen van het ontwerp in documentatie zodat de implementatie op een later moment door de organisatie zelf of een externe partner gerealiseerd kan worden. Hierbij is ook aandacht besteed aan het inbedden van de innovatie in bestaande structuren. Een belangrijk aspect van overdraagbaarheid is dat de waarde van het ontwerp ook zonder directe aanwezigheid van de ontwerper/onderzoeker begrepen en voortgezet kan worden. 
    </p>
    <p>
      Dat in deze Deliver-fase geen “fysiek eindproduct” wordt opgeleverd, betekent niet dat het resultaat vrijblijvend is. Het prototype is immers zodanig ontworpen en getest dat de organisatie een solide vertrekpunt heeft voor implementatie. Feitelijk is ervoor gezorgd dat alle bouwstenen – technisch, didactisch en ethisch – klaarstaan om, zodra de organisatie daartoe besluit, meer kwantitieve data te verzamelen en te investeren in genoemde innovatieve tools. Zo’n flexibele overdracht was hier extra van belang vanwege ethische randvoorwaarden: door nu te focussen op conceptoverdracht kan de organisatie eerst intern draagvlak creëren, beleidsmatige goedkeuring krijgen en eventuele ethische vragen uitwerken, voordat de AI-tool daadwerkelijk met cliëntgegevens aan de slag gaat. Dit zorgvuldige tempo geeft ruimte om aan alle voorwaarden te voldoen. 
 
    </p>
    <p>
Ter illustratie: uit een nieuwsbericht over AI in Twentse gemeenten blijkt dat privacywetgeving een belangrijke horde is bij AI-toepassingen in de zorg, en dat zorgvuldige toestemming en ethische afwegingen nodig zijn voordat men met echte data aan de slag kan. Dergelijke inzichten onderschrijven de keuze om niet overhaast een eindproduct te implementeren, maar eerst de menselijke en organisatorische factoren op orde te hebben. 
    </p>
<cite>(Onderzoek Naar Inzet Kunstmatige Intelligentie in Twentse Gemeenten En Zorg, z.d.)</cite>
  </section>

  <section>
    <h2>5.3 Ethische implicaties van AI in de zorg</h2>
    <p>
De inzet van kunstmatige intelligentie in de zorg brengt diverse ethische aandachtspunten met zich mee. Hieronder worden de belangrijkste ethische thema’s besproken – privacy, informatiebeveiliging, transparantie, betrouwbaarheid, kwetsbaarheid van cliënten en verantwoordelijkheid & toezicht – en wordt telkens gereflecteerd op wat dit betekent voor het huidige ontwerp en de toekomstige implementatie.
    </p>
    <h3>Privacy (AVG) en informatiebeveiliging</h3>
    <p>
Door al in de ontwerpfase dergelijke privacy-by-design maatregelen toe te passen, wordt het risico op privacy inbreuken sterk verkleind. Mocht in de toekomst het platform toch met echte cliëntgegevens verrijkt worden (bijvoorbeeld om gepersonaliseerde feedback te geven), dan dienen eerst de juridische en ethische kaders daarvoor te worden uitgewerkt, inclusief het vragen van expliciete toestemming aan cliënten of hun wettelijke vertegenwoordigers. Uit recent nieuws rond AI-toepassingen blijkt hoe cruciaal dit is: het delen van persoonsgegevens voor AI in de zorg vereist uiterste zorgvuldigheid, zo niet is het in strijd met de privacywet . In overeenstemming hiermee zou bij een eventuele implementatie een functionaris gegevensbescherming van Alliade betrokken moeten worden om te toetsen of aan alle AVG-eisen is voldaan. <cite>(Onderzoek Naar Inzet Kunstmatige Intelligentie in Twentse Gemeenten En Zorg, n.d.)</cite>
    </p>
    <h3>Transparantie en betrouwbaarheid</h3>
    <p>
    <strong> Transparantie</strong> betreft hier zowel de transparantie van het AI-systeem zelf (uitlegbaarheid van de output) als de openheid richting gebruikers over het feit dát er AI wordt ingezet. Een ethisch risico van AI in de zorg is de zogenoemde black box-werking: complexe algoritmen (zoals deep learning modellen) nemen beslissingen op een manier die zelfs ontwikkelaars niet altijd kunnen herleiden of uitleggen. In een zorgsetting is dit problematisch, omdat het voor professionals en cliënten onduidelijk kan zijn op basis waarvan een bepaald advies of leerinhoud wordt gegeven. In dit project is daarom gekozen voor zoveel mogelijk transparantie in de werking van het systeem, denk aan mogelijkheden om ruwe data in te zien, co creatie met professionals etc. 

    </p>
    <p>
      Naast de systeemtransparantie is <strong>menselijke transparantie</strong> van belang: de organisatie dient openlijk te communiceren dat dit platform AI gebruikt als ondersteunend hulpmiddel. Medewerkers worden aangemoedigd om vragen te stellen en ook kritische kanttekeningen te plaatsen bij de adviezen van het systeem. Het moet duidelijk zijn dat AI-gegenereerde adviezen <em>niet</em> onfeilbaar zijn en dat de professionele inschatting van de begeleider altijd voorop blijft staan. Deze houding voorkomt dat er een blind vertrouwen in de technologie ontstaat. 

    </p>
    <p>
     <strong>Betrouwbaarheid</strong> Het <em>ministerie voor volsgezondheid </strong>waarschuwt dat generatieve AI onjuiste of onvolledige informatie kan produceren, wat kan leiden tot risico’s zoals verkeerde inschattingen van cliënten. In het kader van dit concept prototype zou een onbetrouwbaar advies bijvoorbeeld kunnen leiden tot een onbewezen interventie bij een cliënt, met mogelijk escalatie van probleemgedrag tot gevolg. Daarom dient elke actie te worden gevalideerd door professionals. <cite>(Ministerie van Volksgezondheid, Welzijn en Sport, 2025) <cite/>

    </p>
    <p>
Toch blijft waakzaamheid geboden bij betrouwbaarheid, zeker als het systeem zichzelf lerend of adaptief zou worden. Er is daarom een rekening gehouden met <em>continue validatie:</em> bij daadwerkelijke implementatie zou periodiek (bijvoorbeeld elke maand) een multidisciplinair team een steekproef van de AI-adviezen evalueren op juistheid en overeenstemming met de Triple-C-methodiek. Eventuele afwijkingen of vreemde aanbevelingen zouden tijdig worden gecorrigeerd of bijgesteld.
    </p>
    <p>
Een ander aspect van betrouwbaarheid is bias (vertekening). AI-systemen baseren zich op data en patronen die mogelijk niet representatief zijn voor elke individuele cliënt. Uit onderzoek blijkt dat algoritmen vaak gebouwd zijn op de “gemiddelde” patiënt en minder goed werken voor mensen die buiten die gemiddelde groep vallen. In onze context zou dat kunnen betekenen dat de AI beter raad weet met standaardsituaties, maar mogelijk tekortschiet bij zeer unieke of complexe gevallen, bijvoorbeeld cliënten met een zeldzame combinatie van beperkingen. Het gevaar is dat bepaalde cliënten niet de passende ondersteuning krijgen als de AI-adviezen klakkeloos zouden worden gevolgd. Daarom is ervoor gekozen om de AI niet autonoom beslissingen te laten nemen, maar altijd de menselijke professional in de loop te houden. Bovendien is de inhoud van het onderzoek modulair, zodat er ruimte is om specifiek maatwerkmateriaal toe te voegen. Daarmee kan bias gedeeltelijk opgevangen worden door expliciete aandacht voor diversiteit in de casuïstiek. Transparantie speelt ook hier: als een advies mogelijk minder betrouwbaar is (bijvoorbeeld omdat de situatie buiten de geleerd parameters valt), zou het systeem dit in de toekomst kunnen aangeven. </p>
<p> Kortom, om transparantie en betrouwbaarheid te bevorderen, hanteert het ontwerp het idee <em>“glasbox in plaats van black box”:</em> zo open mogelijk over de werking en beperkingen, en voortdurend toetsend of de output strookt met de professionele standaard. Dit alles vergroot het vertrouwen in het systeem, zonder dat er naïeve afhankelijkheid ontstaat.
    </p>
    <h3>Kwetsbaarheid van cliënten</h3>
    <p>
      De doelgroep binnen dit onderzoek behoort tot de meest kwetsbare groepen in de zorg. Deze cliënten zijn in grote mate afhankelijk van de ondersteuning door professionals en kunnen vaak niet (volledig) opkomen voor hun eigen belangen of overzien wat het gebruik van technologie voor hen betekent. Daarom verdienen zij extra bescherming wanneer nieuwe interventies of tools worden ingevoerd. 

    </p>
    <p>
Een eerste overweging is dat technologie nooit de menselijke aandacht en empathie mag verdringen, zeker niet bij een doelgroep die juist gebaat is bij echte menselijke relaties (zoals benadrukt in Triple-C). Er bestaat een reëel risico dat in de drang naar efficiëntie AI-tools menselijke interactie gaan vervangen, wat ten koste kan gaan van de persoonlijke benadering. In het debat wordt dit ook breder erkend: zo waarschuwt Van Kolfschooten dat vooral kwetsbare zorgvragers de dupe kunnen worden en dat we bijvoorbeeld het empathisch vermogen kunnen verliezen als we te veel op AI leunen. In dit ontwerp is daarom steeds het uitgangspunt geweest dat de AI ondersteunend is aan – en niet vervangend voor – de menselijke begeleider. Zo worden begleiders doormiddel van de short-form content gestiumuleerd in hen ‘eigen kracht’ te staan. </p> <cite>(Door de opkomst van AI in de zorg lopen kwetsbare patiënten gevaar, betoogt deze onderzoeker, de Volkskrant, zd.)</cite>
    
    <h3>Verantwoordelijkheid en toezicht</h3>
    <p>
   Een cruciale ethische vraag bij AI in de zorg is: Wie draagt de verantwoordelijkheid voor de output en effecten van het systeem? De AI maakt maakt suggesties, maar <strong>de mens (professional en organisatie) blijft te allen tijde verantwoordelijk</strong> voor de beslissingen en handelingen in de begeleiding. Als een begeleider een door de AI voorgestelde aanpak toepast, dan is het nog steeds de begeleider (en uiteindelijk de organisatie) die verantwoordelijk is voor de consequenties. Deze explicitering voorkomt afschuiven van verantwoordelijkheid op “de computer”. Het sluit ook aan bij de geldende professionele standaard: een sociaal werker handelt volgens professionele richtlijnen en ethiek, waarbij technologie hooguit een hulpmiddel is </p>
<cite>(Rothfusz, 2021).</cite>

    
    <p>
Binnen Alliade zelf zal de borging van de verantwoordelijkheid worden vormgegeven door <strong>beleid en richtlijnen</strong> op te stellen. Er wordt voorgesteld om dit op te nemen in het bestaande kwaliteitshandboek van de organisatie, zodat duidelijk is onder welke condities het AI-systeem gebruikt mag worden (bijv. alleen als ondersteunend leermiddel, niet voor formele dossiervoering) en hoe eventuele incidenten gemeld en opgevolgd moeten worden. Ook wordt aangeraden een interne <em>regiegroep</em> of verantwoordelijke aan te wijzen (aandachtsvelder) die de inbedding van de technologie monitort. Deze groep zou periodiek bijeenkomen om gebruikservaringen door te nemen, te bekijken of het gebruik volgens afspraak verloopt en waar nodig bijsturen. Hiermee creëert de organisatie een vorm van intern toezicht.
    </p>
  </section>

  <section>
    <h2>5.4 Overdracht</h2>
    <p>
Een essentieel onderdeel van deze deliverfase vormt de transparant en praktisch toepasbare overdracht aan de organisatie Alliade. In lijn met het ontwerpgericht onderzoek is ervoor gekozen om een volledig functionele, digitale infrastructuur in te richten waarin alle ontwikkelde kennisproducten en tools direct inzetbaar zijn. 
    </p>
    <p>
Concreet is de kennisoverdracht gerealiseerd via een interactieve, live website die intern toegankelijk kan worden gemaakt voor de medewerkers van Alliade. Deze website is zodanig ingericht dat alle onderzoeksinstrumenten – zoals vragenlijsten, decision matrix, fff-ontwerp ‘quiz’ en thematische analyses – volledig geïntegreerd zijn binnen één overzichtelijke omgeving. Dit betekent dat medewerkers geen externe applicaties of diensten hoeven te raadplegen om de onderzoeksresultaten te beheren, interpreteren of actualiseren. De verzameling en analyse van data vinden volledig <em>‘in-house’</em> plaats, wat zorgt voor een veilige, gecontroleerde en AVG-conforme werkomgeving.
    </p>
    <p>
Om een effectieve en dynamische dataverwerking te waarborgen, maakt het platform gebruik van publiekelijk toegankelijke services als Google Firebase als database. Deze keuze is strategisch genomen om ervoor te zorgen dat de organisatie ook na het afstuderen van de onderzoeker de gegenereerde data blijvend kan beheren, verwerken en gebruiken. Door Firebase kunnen gegevens afkomstig van begeleiders, bijvoorbeeld via enquêtes en reflectieformulieren, automatisch en veilig worden opgeslagen.
<cite>www.firebase.com </cite>

    </p>
    <p>
Daarnaast is gebruikgemaakt van de open-source javascript Go bibliotheek, om de verzamelde data in real-time te visualiseren en te analyseren. Tabellen, grafieken en andere visuele weergaven worden automatisch bijgewerkt wanneer nieuwe gegevens aan de database worden toegevoegd. Dit zorgt ervoor dat inzichten uit de praktijk voortdurend actueel blijven, zonder dat hiervoor extra handmatige acties van de onderzoeker of medewerkers nodig zijn. De onderzoeker heeft hier tijd in <strong>geïnvesteerd</strong>, zodat de organisatie na het afstuderen in staat is snel en effectief te anticiperen op trends en ontwikkelingen binnen het team of de doelgroep.
    </p>
    <p>
De keuze om te investeren in innovatieve technologieën zoals Firebase en of “Go bibliotheek” is bewust gemaakt gedurende het gehele ontwerpproces, met oog voor toekomstbestendigheid en gebruiksvriendelijkheid binnen Alliade. Door deze specifieke digitale infrastructuur kan de organisatie het onderzoek direct en zelfstandig voortzetten. Dit maakt de overdracht niet alleen praktisch, maar ook duurzaam en flexibel: de infrastructuur kan eenvoudig worden aangepast of opgeschaald indien nieuwe inzichten of wensen ontstaan.
    </p>
    <p>
Deze aanpak van overdracht benadrukt het belang van transparantie en toegankelijkheid. Alle ontwikkelde tools zijn gedocumenteerd, handleidingen en instructies zijn direct via de website beschikbaar, en er is aandacht besteed aan het helder communiceren van technische en ethische randvoorwaarden. Hiermee wordt gezorgd dat het eigenaarschap van het concept na afronding van dit onderzoek volledig bij Alliade ligt, waarmee aan de uitgangspunten van ontwerpgericht onderzoek wordt voldaan: impact creëren die blijvend doorwerkt in de praktijk.
    </p>
  </section>

  <section>
    <h2>5.5 Toekomstvisie en verdere innovatie</h2>
    <p>
      Bij het afsluiten van de deliverfase wordt tenslotte een blik vooruit geworpen. Technologie ontwikkelt zich in hoog tempo – exponentieel, zoals vaak wordt gezegd – en dat geldt zeker voor AI. Wat vandaag een innovatieve oplossing is, kan over enkele jaren, maanden of dagen weer ingehaald zijn door nieuwe mogelijkheden. Daarom is het van belang om een toekomstvisie te integreren.

    </p>
    <p>
      <strong>Voorbereid op technologische vooruitgang:</strong> Het ontwerp is opzettelijk flexibel gehouden. Zoals beschreven in §5.6 is de architectuur modulair en schaalbaar. Dit betekent bijvoorbeeld dat, mocht er in de nabije toekomst een AI-model beschikbaar komen dat specifiek getraind is op de gehandicaptenzorg of op de Nederlandse taal in zorgcontext, het platform relatief eenvoudig met zo’n model kan worden uitgerust. Hiermee blijft de oplossing up-to-date met de stand van de techniek. Ook kan gedacht worden aan het toevoegen van nieuwe functionaliteiten, zoals spraakgestuurde input of het integreren van sensorische data (bijvoorbeeld het platform koppelen aan wearables of domotica om gedragspatronen van cliënten te detecteren, voor zover dit ethisch verantwoord is. Het is nadrukkelijk aangeraden om de samenwerking met Alliade haar eigen technische tak en kennisinstellingen voort te zetten, zodat Alliade mee kan groeien met innovaties.

    </p>
    <p>
<strong>Borging van waarden bij verdere innovatie:</strong> In de toekomstvisie wordt benadrukt dat ongeacht hoe de technologie evolueert, de kernwaarden van het sociale domein en de Triple-C werkwijze het kompas moeten blijven. Technologische vernieuwing mag nooit een doel op zich worden; het is alleen gerechtvaardigd als het bijdraagt aan mensgerichte zorg, empowerment van cliënten en ondersteuning van professionals. Dit principe is verankerd in de huidige oplossing en moet ook bij uitbreidingen bewaakt worden. Daarom is voorgesteld om bij elke belangrijke update of nieuwe functionaliteit van het platform een <em>ethische review,</em> te doen (bij voorkeur met betrokkenheid van een ervaringsdeskundige). Zo blijft men alert dat nieuwe features – hoe aantrekkelijk ook technologisch – niet onbedoeld de relatie centraal (cliënt-begeleider) ondermijnen of nieuwe privacyrisico’s introduceren. De Europese en landelijke regelgeving rondom AI zal naar verwachting ook verder concretiseren; Alliade zou hier proactief op in kunnen spelen door pilots zoals deze in te bedden in een breder kader van<em> Responsible Innovation.</em> 
    </p>
  </section>

  <section>
    <h2>Conclusie</h2>
    <p>
In conclusie schetst de Deliver-fase een toekomst waarin de AI-gestuurde Triple-C interventie verder evolueert hand in hand met technologische ontwikkelingen. De organisatie is toegerust met een overdraagbaar concept en bewustzijn om deze innovatie voort te zetten. De erkenning dat ontwikkelingen exponentieel gaan, maakt dat er nu al een adaptieve houding is gecreëerd – een combinatie van enthousiasme voor mogelijkheden en voorzichtigheid om het menselijk aspect te bewaken. Dit is wellicht de belangrijkste uitkomst van allemaal: een oplossing die niet alleen in het hier en nu waarde biedt, maar die ook voorbereid is op de dag van morgen, met behouden van de ziel van het sociaal werk. Zo wordt de belofte van technologie verbonden met de kracht van menselijke zorg, in een voortdurend lerend proces dat bijdraagt aan betekenisvolle innovaties in de gehandicaptenzorg.
    </p>
    <p>
Met andere woorden, de afronding van dit ontwepdossier is feitelijk het begin van een nieuwe fase, waarin de organisatie verder bouwt aan een betere toekomst.    </p>
  </section>
</article> 


  </main>

  <footer>
    <p>&copy; 2025 Houtje Inc. Alle rechten voorbehouden.</p>
  </footer>

  <!-- Dynamische TOC JavaScript -->

  <!-- (Optioneel) Extra script voor andere interactieve elementen -->
  <!-- <script src="js/extraInteractivity.js"></script> -->
    <script src="js/dynamicToc.js"></script>
</body>
</html>
